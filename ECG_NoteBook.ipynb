{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'ecg_data'\n",
    "train_data_path = 'ecg_data\\mitbih_train.csv'\n",
    "test_data_path = 'ecg_data\\mitbih_test.csv'\n",
    "Classes: {'N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path,header=None)\n",
    "test_df = pd.read_csv(test_data_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87554 entries, 0 to 87553\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 125.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[187]=train_df[187].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    72471\n",
      "4     6431\n",
      "2     5788\n",
      "1     2223\n",
      "3      641\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "equilibre=train_df[187].value_counts()\n",
    "print(equilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#saving data\n",
    "# for index, row in tqdm(train_df.iterrows()):\n",
    "#     if index%50==0:\n",
    "#         img = row[:187]\n",
    "#         label = row[187]\n",
    "#         plt.clf()\n",
    "#         plt.plot(img)\n",
    "#         plt.savefig(os.path.join(str(int(label)),str(index)+'.jpg'))\n",
    "#     plt.show()\n",
    "#         print(\"label\", label)\n",
    "#     if index == 100:\n",
    "#         break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for index, row in tqdm(train_df.iterrows()):\n",
    "#     if index%50==0:\n",
    "#         img = row[:187]\n",
    "#         label = row[187]\n",
    "#         plt.clf()\n",
    "#         plt.plot(img)\n",
    "#         path_to_save = os.path.join('ecg_data',os.path.join(str(int(label)),str(index)+'.jpg'))\n",
    "#         plt.savefig(path_to_save)\n",
    "#         img = cv2.imread(path_to_save)\n",
    "#         img = img[36:-36,55:-53,:]\n",
    "#         cv2.imwrite(path_to_save, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[15001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# settings \n",
    "img_height  = 128\n",
    "img_width  = 128 \n",
    "img_channel = 1\n",
    "batch_size  = 2\n",
    "nb_classes = 5\n",
    "epochs = 30\n",
    "\n",
    "trainset = 'train'\n",
    "# testset = './dataset/test'\n",
    "# validset = './dataset/valid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 747 images belonging to 5 classes.\n",
      "Found 129 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    trainset,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    subset='training',class_mode='categorical', color_mode ='grayscale') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    trainset,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',class_mode='categorical',color_mode ='grayscale') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def alexnet_model(img_shape=(224, 224, 3), n_classes=5, l2_reg=0.,weights=None):\n",
    "\n",
    "    # Initialize model\n",
    "    alexnet = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    alexnet.add(Conv2D(16, (11, 11), input_shape=img_shape, padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    alexnet.add(Conv2D(23, (5, 5), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 3\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 4\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "\n",
    "    # Layer 5\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 6\n",
    "    alexnet.add(Flatten())\n",
    "    alexnet.add(Dense(512))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    alexnet.add(Dense(1024))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('relu'))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 8\n",
    "    alexnet.add(Dense(n_classes))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('softmax'))\n",
    "\n",
    "    if weights is not None:\n",
    "        alexnet.load_weights(weights)\n",
    "\n",
    "    return alexnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\20111\\anaconda3\\envs\\New\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "alex = alexnet_model(img_shape=(128, 128, 1), n_classes=5, l2_reg=0.,weights=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "373/373 [==============================] - 148s 396ms/step - loss: 0.8068 - acc: 0.8255 - val_loss: 0.7205 - val_acc: 0.8359\n",
      "Epoch 2/30\n",
      "373/373 [==============================] - 152s 409ms/step - loss: 0.7518 - acc: 0.8268 - val_loss: 1.4594 - val_acc: 0.8359\n",
      "Epoch 3/30\n",
      "373/373 [==============================] - 147s 395ms/step - loss: 0.6985 - acc: 0.8282 - val_loss: 0.7508 - val_acc: 0.8125\n",
      "Epoch 4/30\n",
      "373/373 [==============================] - 147s 395ms/step - loss: 0.6919 - acc: 0.8255 - val_loss: 1.0166 - val_acc: 0.8125\n",
      "Epoch 5/30\n",
      "373/373 [==============================] - 146s 391ms/step - loss: 0.6873 - acc: 0.8242 - val_loss: 0.6021 - val_acc: 0.8359\n",
      "Epoch 6/30\n",
      "373/373 [==============================] - 146s 393ms/step - loss: 0.6678 - acc: 0.8255 - val_loss: 1.3950 - val_acc: 0.6406\n",
      "Epoch 7/30\n",
      "373/373 [==============================] - 138s 371ms/step - loss: 0.6469 - acc: 0.8282 - val_loss: 0.6325 - val_acc: 0.8516\n",
      "Epoch 8/30\n",
      "373/373 [==============================] - 168s 451ms/step - loss: 0.6632 - acc: 0.8228 - val_loss: 0.8238 - val_acc: 0.6797\n",
      "Epoch 9/30\n",
      "373/373 [==============================] - 169s 453ms/step - loss: 0.6266 - acc: 0.8309 - val_loss: 0.6553 - val_acc: 0.8203\n",
      "Epoch 10/30\n",
      "373/373 [==============================] - 167s 448ms/step - loss: 0.6496 - acc: 0.8231 - val_loss: 0.5850 - val_acc: 0.8281\n",
      "Epoch 11/30\n",
      "373/373 [==============================] - 166s 446ms/step - loss: 0.6364 - acc: 0.8280 - val_loss: 0.6006 - val_acc: 0.8359\n",
      "Epoch 12/30\n",
      "373/373 [==============================] - 168s 449ms/step - loss: 0.6549 - acc: 0.8215 - val_loss: 0.6317 - val_acc: 0.8047\n",
      "Epoch 13/30\n",
      "373/373 [==============================] - 167s 448ms/step - loss: 0.6357 - acc: 0.8268 - val_loss: 0.6007 - val_acc: 0.8281\n",
      "Epoch 14/30\n",
      "373/373 [==============================] - 159s 426ms/step - loss: 0.6523 - acc: 0.8268 - val_loss: 0.6031 - val_acc: 0.8359\n",
      "Epoch 15/30\n",
      "373/373 [==============================] - 176s 471ms/step - loss: 0.6415 - acc: 0.8242 - val_loss: 0.8799 - val_acc: 0.7578\n",
      "Epoch 16/30\n",
      "373/373 [==============================] - 176s 471ms/step - loss: 0.6351 - acc: 0.8255 - val_loss: 0.6999 - val_acc: 0.8203\n",
      "Epoch 17/30\n",
      "373/373 [==============================] - 195s 521ms/step - loss: 0.6238 - acc: 0.8295 - val_loss: 0.4869 - val_acc: 0.8750\n",
      "Epoch 18/30\n",
      "373/373 [==============================] - 192s 516ms/step - loss: 0.6300 - acc: 0.8255 - val_loss: 0.5170 - val_acc: 0.8359\n",
      "Epoch 19/30\n",
      "373/373 [==============================] - 187s 503ms/step - loss: 0.6290 - acc: 0.8255 - val_loss: 0.5472 - val_acc: 0.8359\n",
      "Epoch 20/30\n",
      "373/373 [==============================] - 182s 488ms/step - loss: 0.6467 - acc: 0.8295 - val_loss: 0.6836 - val_acc: 0.8359\n",
      "Epoch 21/30\n",
      "373/373 [==============================] - 138s 371ms/step - loss: 0.6918 - acc: 0.8201 - val_loss: 0.5899 - val_acc: 0.8359\n",
      "Epoch 22/30\n",
      "373/373 [==============================] - 138s 370ms/step - loss: 0.6396 - acc: 0.8282 - val_loss: 0.5468 - val_acc: 0.8359\n",
      "Epoch 23/30\n",
      "373/373 [==============================] - 138s 369ms/step - loss: 0.6214 - acc: 0.8242 - val_loss: 0.5161 - val_acc: 0.8359\n",
      "Epoch 24/30\n",
      "373/373 [==============================] - 138s 371ms/step - loss: 0.6321 - acc: 0.8242 - val_loss: 0.5578 - val_acc: 0.8359\n",
      "Epoch 25/30\n",
      "373/373 [==============================] - 139s 372ms/step - loss: 0.6084 - acc: 0.8311 - val_loss: 0.5090 - val_acc: 0.8359\n",
      "Epoch 26/30\n",
      "373/373 [==============================] - 137s 369ms/step - loss: 0.6664 - acc: 0.8199 - val_loss: 0.7701 - val_acc: 0.7891\n",
      "Epoch 27/30\n",
      "373/373 [==============================] - 137s 367ms/step - loss: 0.6550 - acc: 0.8268 - val_loss: 0.6496 - val_acc: 0.8359\n",
      "Epoch 28/30\n",
      "373/373 [==============================] - 139s 371ms/step - loss: 0.6481 - acc: 0.8242 - val_loss: 0.4971 - val_acc: 0.8281\n",
      "Epoch 29/30\n",
      "373/373 [==============================] - 138s 370ms/step - loss: 0.6129 - acc: 0.8309 - val_loss: 0.4943 - val_acc: 0.8203\n",
      "Epoch 30/30\n",
      "373/373 [==============================] - 138s 369ms/step - loss: 0.6484 - acc: 0.8201 - val_loss: 0.6142 - val_acc: 0.7891\n"
     ]
    }
   ],
   "source": [
    "history = alex.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
